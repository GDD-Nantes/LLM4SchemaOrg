n_ctx: 16000 # Context span
n_gpu_layers: 4 # Number of GPU layers to share load from CPU, put a high number and progressively decrease it untill OOM error is gone.
chat_format: "llama-2" # By default